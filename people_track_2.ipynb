{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPi14h0XhGXLG+ZAgY1DuUn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wolf-of-github/AES-demonstration/blob/main/people_track_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wosijNr2BN8H",
        "outputId": "cc02d970-f2e6-432e-9bbb-3f73c7848552"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U insightface onnxruntime-gpu"
      ],
      "metadata": {
        "id": "eFgGvCO9CIU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U albumentations"
      ],
      "metadata": {
        "id": "W_j2Nf3dCjx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "6zwoBcSVC3__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fb9009-1d53-4e47-e6b9-4dc47e8836ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall current version\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "\n",
        "# Install compatible version\n",
        "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Reinstall insightface\n",
        "!pip install -U insightface"
      ],
      "metadata": {
        "id": "eEuzG7I_DA5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U insightface"
      ],
      "metadata": {
        "id": "xAAvCl5CD8mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime-gpu"
      ],
      "metadata": {
        "id": "H-b-3FLtD-yH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# === Configuration ===\n",
        "video_path = \"/content/gdrive/MyDrive/Project Anthro/Face Recognition/input.mp4\"\n",
        "output_dir = \"/content/gdrive/MyDrive/Project Anthro/Face Recognition/faces\"\n",
        "frame_interval = 10\n",
        "similarity_threshold = 0.5  # Lower = stricter match\n",
        "person_id_counter = 0\n",
        "known_embeddings = []  # [(embedding, folder_name)]\n",
        "\n",
        "# Setup face detector (GPU)\n",
        "app = FaceAnalysis(name=\"buffalo_l\", providers=[\"CUDAExecutionProvider\"])\n",
        "app.prepare(ctx_id=0)\n",
        "\n",
        "# Create output folder\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"❌ ERROR: Could not open video.\")\n",
        "\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(f\"✅ Total frames in video: {total_frames}\")\n",
        "\n",
        "frame_idx = 0\n",
        "saved_count = 0\n",
        "\n",
        "# Progress bar\n",
        "with tqdm(total=total_frames, desc=\"Processing video\") as pbar:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_idx % frame_interval == 0:\n",
        "            height, width = frame.shape[:2]\n",
        "            faces = app.get(frame)\n",
        "\n",
        "            for i, face in enumerate(faces):\n",
        "                x1, y1, x2, y2 = map(int, face.bbox)\n",
        "\n",
        "                if x1 < 0 or y1 < 0 or x2 > width or y2 > height:\n",
        "                    continue\n",
        "\n",
        "                # Get embedding\n",
        "                emb = face.embedding.reshape(1, -1)\n",
        "                match_found = False\n",
        "\n",
        "                for known_emb, folder_name in known_embeddings:\n",
        "                    sim = cosine_similarity(emb, known_emb.reshape(1, -1))[0][0]\n",
        "                    if sim > similarity_threshold:\n",
        "                        person_folder = os.path.join(output_dir, folder_name)\n",
        "                        match_found = True\n",
        "                        break\n",
        "\n",
        "                if not match_found:\n",
        "                    person_id_counter += 1\n",
        "                    folder_name = f\"person_{person_id_counter}\"\n",
        "                    person_folder = os.path.join(output_dir, folder_name)\n",
        "                    os.makedirs(person_folder, exist_ok=True)\n",
        "                    known_embeddings.append((emb, folder_name))\n",
        "\n",
        "                crop = frame[y1:y2, x1:x2]\n",
        "                face_filename = f\"face_{frame_idx}_{i}.jpg\"\n",
        "                cv2.imwrite(os.path.join(person_folder, face_filename), crop)\n",
        "                saved_count += 1\n",
        "\n",
        "        frame_idx += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "cap.release()\n",
        "print(f\"✅ Finished. Saved {saved_count} face crops into {person_id_counter} unique person folders.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9elTUwwCM72",
        "outputId": "29a17918-c343-4095-a592-9826219e8b7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "✅ Total frames in video: 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing video: 100%|██████████| 2000/2000 [01:30<00:00, 22.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Finished. Saved 573 face crops into 83 unique person folders.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying to avoid back facing people and side profiled people"
      ],
      "metadata": {
        "id": "heDL1e6VNDzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# === Configuration ===\n",
        "video_path = \"/content/gdrive/MyDrive/Project Anthro/Face Recognition/input.mp4\"\n",
        "output_dir = \"/content/gdrive/MyDrive/Project Anthro/Face Recognition/faces\"\n",
        "frame_interval = 10\n",
        "similarity_threshold = 0.5  # Lower = stricter match\n",
        "person_id_counter = 0\n",
        "known_embeddings = []  # [(embedding, folder_name)]\n",
        "\n",
        "# Setup face detector (GPU)\n",
        "app = FaceAnalysis(name=\"buffalo_l\", providers=[\"CUDAExecutionProvider\"])\n",
        "app.prepare(ctx_id=0)\n",
        "\n",
        "# Create output folder\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"❌ ERROR: Could not open video.\")\n",
        "\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(f\"✅ Total frames in video: {total_frames}\")\n",
        "\n",
        "frame_idx = 0\n",
        "saved_count = 0\n",
        "\n",
        "# Progress bar\n",
        "with tqdm(total=total_frames, desc=\"Processing video\") as pbar:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_idx % frame_interval == 0:\n",
        "            height, width = frame.shape[:2]\n",
        "            faces = app.get(frame)\n",
        "\n",
        "            for i, face in enumerate(faces):\n",
        "                x1, y1, x2, y2 = map(int, face.bbox)\n",
        "                if x1 < 0 or y1 < 0 or x2 > width or y2 > height:\n",
        "                    continue\n",
        "\n",
        "                # === Orientation check: skip back or profile faces ===\n",
        "                kps = face.kps\n",
        "                if kps is None or len(kps) < 5:\n",
        "                    continue  # Landmark extraction failed → likely turned away\n",
        "\n",
        "                left_eye, right_eye = kps[0], kps[1]\n",
        "                eye_dx = abs(left_eye[0] - right_eye[0])\n",
        "                eye_dy = abs(left_eye[1] - right_eye[1])\n",
        "                eye_distance = np.hypot(eye_dx, eye_dy)\n",
        "\n",
        "                if eye_distance < 10:  # Too close → likely not frontal\n",
        "                    continue\n",
        "                # === End orientation check ===\n",
        "\n",
        "                # Get embedding\n",
        "                emb = face.embedding.reshape(1, -1)\n",
        "                match_found = False\n",
        "\n",
        "                for known_emb, folder_name in known_embeddings:\n",
        "                    sim = cosine_similarity(emb, known_emb.reshape(1, -1))[0][0]\n",
        "                    if sim > similarity_threshold:\n",
        "                        person_folder = os.path.join(output_dir, folder_name)\n",
        "                        match_found = True\n",
        "                        break\n",
        "\n",
        "                if not match_found:\n",
        "                    person_id_counter += 1\n",
        "                    folder_name = f\"person_{person_id_counter}\"\n",
        "                    person_folder = os.path.join(output_dir, folder_name)\n",
        "                    os.makedirs(person_folder, exist_ok=True)\n",
        "                    known_embeddings.append((emb, folder_name))\n",
        "\n",
        "                crop = frame[y1:y2, x1:x2]\n",
        "                face_filename = f\"face_{frame_idx}_{i}.jpg\"\n",
        "                cv2.imwrite(os.path.join(person_folder, face_filename), crop)\n",
        "                saved_count += 1\n",
        "\n",
        "        frame_idx += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "cap.release()\n",
        "print(f\"✅ Finished. Saved {saved_count} face crops into {person_id_counter} unique person folders.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yxhoIsbMxh2",
        "outputId": "1b5f1085-1777-4ba5-8a99-56fe5535cdac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "✅ Total frames in video: 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing video: 100%|██████████| 2000/2000 [01:24<00:00, 23.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Finished. Saved 532 face crops into 73 unique person folders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stricter params to avoid side profiles"
      ],
      "metadata": {
        "id": "wffO5dDLOWti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# === Configuration ===\n",
        "video_path = \"/content/gdrive/MyDrive/Project Anthro/Face Recognition/input.mp4\"\n",
        "output_dir = \"/content/gdrive/MyDrive/Project Anthro/Face Recognition/faces\"\n",
        "frame_interval = 10\n",
        "similarity_threshold = 0.15\n",
        "person_id_counter = 0\n",
        "known_embeddings = []  # [(embedding, folder_name)]\n",
        "\n",
        "# Setup face detector (GPU)\n",
        "app = FaceAnalysis(name=\"buffalo_l\", providers=[\"CUDAExecutionProvider\"])\n",
        "app.prepare(ctx_id=0)\n",
        "\n",
        "# Create output folder\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"❌ ERROR: Could not open video.\")\n",
        "\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(f\"✅ Total frames in video: {total_frames}\")\n",
        "\n",
        "frame_idx = 0\n",
        "saved_count = 0\n",
        "\n",
        "# Progress bar\n",
        "with tqdm(total=total_frames, desc=\"Processing video\") as pbar:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_idx % frame_interval == 0:\n",
        "            height, width = frame.shape[:2]\n",
        "            faces = app.get(frame)\n",
        "\n",
        "            for i, face in enumerate(faces):\n",
        "                x1, y1, x2, y2 = map(int, face.bbox)\n",
        "                if x1 < 0 or y1 < 0 or x2 > width or y2 > height:\n",
        "                    continue\n",
        "\n",
        "                # === Orientation check: skip back or side-profile faces ===\n",
        "                kps = face.kps\n",
        "                if kps is None or len(kps) < 5:\n",
        "                    continue  # Landmark extraction failed → likely turned away or profile\n",
        "\n",
        "                left_eye, right_eye = kps[0], kps[1]\n",
        "                eye_dist = np.linalg.norm(left_eye - right_eye)\n",
        "                if eye_dist < 10:\n",
        "                    continue  # Eyes too close or overlapping → likely only one eye visible → side/back view\n",
        "                # === End orientation check ===\n",
        "\n",
        "                # Get embedding\n",
        "                emb = face.embedding.reshape(1, -1)\n",
        "                match_found = False\n",
        "\n",
        "                for known_emb, folder_name in known_embeddings:\n",
        "                    sim = cosine_similarity(emb, known_emb.reshape(1, -1))[0][0]\n",
        "                    if sim > similarity_threshold:\n",
        "                        person_folder = os.path.join(output_dir, folder_name)\n",
        "                        match_found = True\n",
        "                        break\n",
        "\n",
        "                if not match_found:\n",
        "                    person_id_counter += 1\n",
        "                    folder_name = f\"person_{person_id_counter}\"\n",
        "                    person_folder = os.path.join(output_dir, folder_name)\n",
        "                    os.makedirs(person_folder, exist_ok=True)\n",
        "                    known_embeddings.append((emb, folder_name))\n",
        "\n",
        "                crop = frame[y1:y2, x1:x2]\n",
        "                face_filename = f\"face_{frame_idx}_{i}.jpg\"\n",
        "                cv2.imwrite(os.path.join(person_folder, face_filename), crop)\n",
        "                saved_count += 1\n",
        "\n",
        "        frame_idx += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "cap.release()\n",
        "print(f\"✅ Finished. Saved {saved_count} face crops into {person_id_counter} unique person folders.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vel9RgP2OcZw",
        "outputId": "c0df4a12-41c2-42ad-aa14-2caa0c2b54fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "✅ Total frames in video: 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing video: 100%|██████████| 2000/2000 [01:22<00:00, 24.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Finished. Saved 532 face crops into 14 unique person folders.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-by-step identificaion, simply extracting all faces"
      ],
      "metadata": {
        "id": "SNsuj0IGowL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "prj_dir = \"/content/gdrive/MyDrive/Project Anthro/Face Recognition/\"\n",
        "test_file = os.path.join(prj_dir, \"write_test.json\")\n",
        "\n",
        "try:\n",
        "    # Try creating and writing a small JSON file\n",
        "    with open(test_file, \"w\") as f:\n",
        "        json.dump({\"test\": \"success\"}, f)\n",
        "    print(\"✅ JSON write test successful.\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"❌ Failed to write to JSON file.\")\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj-Z_zWdMx6W",
        "outputId": "474a43c4-ac9b-444c-e405-abe4a50d1717"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ JSON write test successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "results = []\n",
        "\n",
        "prj_dir = \"/content/gdrive/MyDrive/Project Anthro/Face Recognition/\"\n",
        "video_path = os.path.join(prj_dir, \"input.mp4\")\n",
        "output_dir = os.path.join(prj_dir, \"all-faces-2\")\n",
        "frame_interval = 10\n",
        "\n",
        "# Setup face detector (GPU)\n",
        "app = FaceAnalysis(name=\"buffalo_l\", providers=[\"CUDAExecutionProvider\"])\n",
        "app.prepare(ctx_id=0)\n",
        "\n",
        "# Create output folder\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(\"ERROR: Could not open video.\")\n",
        "\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "frame_idx = 0\n",
        "saved_count = 0\n",
        "\n",
        "with tqdm(total=total_frames, desc=\"Processing video\") as pbar:\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_idx % frame_interval == 0:\n",
        "\n",
        "            height, width = frame.shape[:2]\n",
        "            faces = app.get(frame)\n",
        "\n",
        "            for i, face in enumerate(faces):\n",
        "                x1, y1, x2, y2 = map(int, face.bbox)\n",
        "\n",
        "                # Skip if box is out of frame\n",
        "                if x1 < 0 or y1 < 0 or x2 > width or y2 > height:\n",
        "                    continue\n",
        "\n",
        "                # Orientation check: landmarks required\n",
        "                kps = face.kps\n",
        "                if kps is None or len(kps) < 2:\n",
        "                    continue\n",
        "\n",
        "                # Crop and save face\n",
        "                crop = frame[y1:y2, x1:x2]\n",
        "                face_filename = f\"face_{frame_idx}_{i}.jpg\"\n",
        "                face_path = os.path.join(output_dir, face_filename)\n",
        "                cv2.imwrite(face_path, crop)\n",
        "                saved_count += 1\n",
        "\n",
        "                # Compute normalized eye distance\n",
        "                left_eye = kps[0]\n",
        "                right_eye = kps[1]\n",
        "                euclidean_distance = np.linalg.norm(left_eye - right_eye)\n",
        "                bbox_width = x2 - x1\n",
        "                normalized_eye_distance = euclidean_distance / bbox_width\n",
        "\n",
        "                normalized_lip_distance = None\n",
        "                if len(kps) >= 5:\n",
        "                    left_lip = kps[3]\n",
        "                    right_lip = kps[4]\n",
        "                    lip_distance = np.linalg.norm(left_lip - right_lip)\n",
        "                    normalized_lip_distance = lip_distance / bbox_width\n",
        "\n",
        "                # Calculate nose placement relative to eyes\n",
        "                nose_position = None\n",
        "                if len(kps) >= 3:\n",
        "                    nose = kps[2]\n",
        "                    if nose[0] < min(left_eye[0], right_eye[0]):\n",
        "                        nose_position = -1\n",
        "                    elif nose[0] > max(left_eye[0], right_eye[0]):\n",
        "                        nose_position = 1\n",
        "                    else:\n",
        "                        nose_position = 0\n",
        "\n",
        "                result = {\n",
        "                    \"filename\": face_filename,\n",
        "                    \"normalized_eye_distance\": float(normalized_eye_distance),\n",
        "                    \"normalized_lip_distance\": float(normalized_lip_distance) if normalized_lip_distance is not None else None,\n",
        "                    \"det_score\": float(face.det_score),\n",
        "                    \"orientation_magnitude\": None,\n",
        "                    \"mask\": None,\n",
        "                    \"nose_placement\": nose_position\n",
        "                }\n",
        "\n",
        "                if hasattr(face, 'pose') and face.pose is not None:\n",
        "                    yaw, pitch, roll = face.pose\n",
        "                    orientation_magnitude = np.linalg.norm([yaw, pitch, roll])\n",
        "                    result[\"orientation_magnitude\"] = float(orientation_magnitude)\n",
        "\n",
        "                if hasattr(face, 'mask'):\n",
        "                    result[\"mask\"] = face.mask\n",
        "\n",
        "                results.append(result)\n",
        "\n",
        "\n",
        "        frame_idx += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "cap.release()\n",
        "print(f\"Finished. Saved {saved_count} face crops to {output_dir}\\n\")\n",
        "\n",
        "# Save results to JSON file in prj_dir\n",
        "json_output_path = os.path.join(prj_dir, \"face_metrics.json\")\n",
        "\n",
        "# Save or create JSON file\n",
        "if os.path.exists(json_output_path):\n",
        "    with open(json_output_path, \"r\") as f:\n",
        "        existing_data = json.load(f)\n",
        "    existing_data.extend(results)\n",
        "    with open(json_output_path, \"w\") as f:\n",
        "        json.dump(existing_data, f, indent=4)\n",
        "else:\n",
        "    with open(json_output_path, \"w\") as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "\n",
        "print(f\"Face metrics saved to {json_output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBdSfw_iodz3",
        "outputId": "47dd9e8c-35e7-44ec-f157-6230465e0def"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing video: 100%|██████████| 2000/2000 [01:23<00:00, 24.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished. Saved 573 face crops to /content/gdrive/MyDrive/Project Anthro/Face Recognition/all-faces-2\n",
            "\n",
            "Face metrics saved to /content/gdrive/MyDrive/Project Anthro/Face Recognition/face_metrics.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('hi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kby9EBo1sDeL",
        "outputId": "c035a957-5adc-4c30-f646-d216c587f5c8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n"
          ]
        }
      ]
    }
  ]
}